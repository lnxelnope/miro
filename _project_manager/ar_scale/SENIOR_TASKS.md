# Senior Tasks ‚Äî AR Scale Ruler System

> **‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö:** Senior Developer / AI Agent  
> **‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó:** Logic, Integration, Prompt Engineering  
> **‡∏ó‡∏≥‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å:** Junior ‡∏ó‡∏≥ JUNIOR_TASKS.md ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î  
> **‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î:** 1 ‡∏°‡∏µ.‡∏Ñ. 2026

---

## üìä ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞

```
Phase 1 (Smart Prompt):        ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  100% (S1-S3) ‚úÖ
Phase 2 (Local Detection):     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  100% (S4-S7) ‚úÖ
Phase 3 (Real-time AR Camera): ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  100% (S8-S10) ‚úÖ
```

Last updated: 1 ‡∏°‡∏µ.‡∏Ñ. 2026 ‚Äî ‡∏ó‡∏±‡πâ‡∏á 3 Phase implement ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß

---

## Pre-check ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°

‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ Junior ‡∏ó‡∏≥‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß:

- [ ] J1: Isar schema regenerated
- [ ] J2-J5: Widget ‡∏ñ‡∏π‡∏Å‡∏ß‡∏≤‡∏á‡πÉ‡∏ô‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
- [ ] J6: Calibration fields ‡∏ñ‡∏π‡∏Å apply ‡πÉ‡∏ô entry
- [ ] J7: Barrel export file ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡πâ‡∏ß
- [ ] `flutter analyze` ‡πÑ‡∏°‡πà‡∏°‡∏µ error
- [ ] App build + run ‡πÑ‡∏î‡πâ‡∏õ‡∏Å‡∏ï‡∏¥

---

## Phase 1: Smart Gemini Prompt (S1-S3)

### S1. Implement ScaleCalibrationService Logic

**‡πÑ‡∏ü‡∏•‡πå:** `lib/core/ar_scale/services/scale_calibration_service.dart`

‡πÅ‡∏Å‡πâ‡∏ó‡∏∏‡∏Å `TODO: [SENIOR]` ‡πÉ‡∏´‡πâ implement ‡∏à‡∏£‡∏¥‡∏á:

**Logic ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á implement:**

1. `calculatePixelPerCm()`:
   ```
   ‡∏™‡∏π‡∏ï‡∏£‡∏´‡∏•‡∏±‡∏Å:
   pixelPerCm = longestSidePixels / knownLengthCm
   
   ‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏≠‡∏á handle:
   - ‡∏ñ‡πâ‡∏≤ bounding box aspect ratio ‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å real object > 30%
     ‚Üí ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÄ‡∏≠‡∏µ‡∏¢‡∏á ‚Üí ‡πÉ‡∏ä‡πâ diagonal: sqrt(w¬≤ + h¬≤) / knownLengthCm
   - ‡∏ñ‡πâ‡∏≤ aspect ratio ‡∏ï‡∏£‡∏á (¬±15%) ‚Üí ‡πÉ‡∏ä‡πâ longestSide ‡∏ï‡∏£‡∏á‡πÜ
   ```

2. `calibrate()`:
   ```
   1. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì pixelPerCm
   2. ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ plateBoundingBox:
      - plateDiameter = max(plate.width, plate.height) / pixelPerCm
      - plateArea = œÄ √ó (diameter/2)¬≤
   3. estimateVolume:
      - plate: œÄ √ó (d/2)¬≤ √ó 2.5cm (shallow)
      - bowl: œÄ √ó (d/2)¬≤ √ó 7.0cm (deep) √ó 0.6 (not full)
   4. adjustConfidenceForPerspective
   5. ‡∏ñ‡πâ‡∏≤ adjusted confidence < 0.65 ‚Üí return null
   ```

3. `adjustConfidenceForPerspective()`:
   ```
   expectedAspectRatio = knownLengthCm / knownWidthCm
   actualAspectRatio = longestSide / shortestSide
   
   deviation = abs(expected - actual) / expected
   
   ‡∏ñ‡πâ‡∏≤ deviation > 0.5 ‚Üí confidence √ó 0.5 (perspective ‡∏°‡∏≤‡∏Å)
   ‡∏ñ‡πâ‡∏≤ deviation > 0.3 ‚Üí confidence √ó 0.7
   ‡∏ñ‡πâ‡∏≤ deviation > 0.15 ‚Üí confidence √ó 0.85
   ‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‚Üí confidence √ó 1.0 (‡∏õ‡∏Å‡∏ï‡∏¥)
   ```

---

### S2. ‡πÅ‡∏Å‡πâ Gemini Prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Image Analysis

**‡πÑ‡∏ü‡∏•‡πå:** `lib/core/ai/gemini_service.dart`

**‡πÅ‡∏Å‡πâ method:** `_getImageAnalysisPrompt()`

**‡πÄ‡∏û‡∏¥‡πà‡∏° section ‡πÉ‡∏´‡∏°‡πà‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å STEP 4 ‚Äî CROSS-REFERENCE:**

```
Step 5 ‚Äî REFERENCE OBJECT DETECTION (for portion accuracy):
Scan the image for standard reference objects placed near the food:
- Cutlery: Fork (~19.5cm), Spoon (~17cm), Knife (~22cm), Chopsticks (~23cm)
- Cards: Credit card (8.56√ó5.4cm), ID card
- Coins: visible coins of any denomination

If ANY reference object is found near the food:
1. Report it in "reference_objects" array
2. Use the known real-world size to estimate the plate/bowl diameter
3. Use the plate size to more accurately estimate the total food weight (serving_grams)

If NO reference object is found, simply skip the "reference_objects" field.

Add to your JSON response (ONLY if reference objects are found):
"reference_objects": [
  {
    "type": "dining_fork",
    "confidence": 0.92,
    "known_length_cm": 19.5
  }
],
"plate_measurement": {
  "estimated_diameter_cm": 22.5,
  "estimated_area_cm2": 397.6,
  "estimated_volume_ml": 450
}
```

**‡πÅ‡∏Å‡πâ method:** `analyzeFoodImage()` 

‡πÄ‡∏û‡∏¥‡πà‡∏° logic: ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ calibrationData ‚Üí ‡πÄ‡∏û‡∏¥‡πà‡∏° hint ‡πÉ‡∏ô prompt:
```dart
// ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ local calibration data ‡∏à‡∏≤‡∏Å ML Kit ‚Üí ‡πÄ‡∏û‡∏¥‡πà‡∏° hint ‡πÉ‡∏´‡πâ Gemini
if (calibrationHint != null) {
  prompt += '\n\n$calibrationHint';
}
```

**‡πÄ‡∏û‡∏¥‡πà‡∏° parameter ‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏ô `analyzeFoodImage()`:**
```dart
String? calibrationHint, // ‡∏à‡∏≤‡∏Å CalibrationResult.toPromptHint()
```

---

### S3. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Phase 1

1. ‡∏ñ‡πà‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡∏≠‡∏≤‡∏´‡∏≤‡∏£ + ‡∏ä‡πâ‡∏≠‡∏ô ‚Üí ‡∏™‡πà‡∏á Gemini ‚Üí ‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡πà‡∏≤‡∏°‡∏µ `reference_objects` ‡πÉ‡∏ô response
2. ‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡πà‡∏≤ `FoodAnalysisResult.isCalibrated` = true
3. ‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡πà‡∏≤ `CalibrationBadge` ‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏ô UI

---

## Phase 2: Local Detection + Enhanced (S4-S7)

### S4. Implement ReferenceDetectorService

**‡πÑ‡∏ü‡∏•‡πå:** `lib/core/ar_scale/services/reference_detector_service.dart`

**‡πÅ‡∏Å‡πâ‡∏ó‡∏∏‡∏Å TODO:**

1. `initialize()`:
   ```dart
   import 'package:google_mlkit_object_detection/google_mlkit_object_detection.dart';

   late ObjectDetector _objectDetector;
   
   final options = ObjectDetectorOptions(
     mode: DetectionMode.single,
     classifyObjects: true,
     multipleObjects: true,
   );
   _objectDetector = ObjectDetector(options: options);
   ```

2. `detectFromImage()`:
   ```dart
   final inputImage = InputImage.fromFilePath(imageFile.path);
   final objects = await _objectDetector.processImage(inputImage);
   
   // Filter for reference objects
   for (final obj in objects) {
     for (final label in obj.labels) {
       // Match label.text ‡∏Å‡∏±‡∏ö ReferenceObjectType.mlKitLabels
       // ‡∏™‡∏£‡πâ‡∏≤‡∏á DetectedReferenceObject
     }
   }
   ```

3. Handle ML Kit label mapping:
   - ML Kit base model ‡∏≠‡∏≤‡∏à return generic labels ("Cutlery", "Tableware")
   - ‡∏ï‡πâ‡∏≠‡∏á map ‡∏Å‡∏±‡∏ö ReferenceObjectType ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
   - ‡∏ñ‡πâ‡∏≤ "Cutlery" ‚Üí ‡πÉ‡∏ä‡πâ aspect ratio ‡πÅ‡∏¢‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô fork/spoon/knife
     - aspect ratio > 6:1 ‚Üí chopsticks
     - aspect ratio > 3:1 ‚Üí fork or knife
     - aspect ratio 2:1 to 3:1 ‚Üí spoon

---

### S5. Integrate Detection ‡πÉ‡∏ô ImageAnalysisPreviewScreen

**‡πÑ‡∏ü‡∏•‡πå:** `lib/features/health/presentation/image_analysis_preview_screen.dart`

**Flow ‡πÉ‡∏´‡∏°‡πà:**
```
1. User ‡∏ñ‡πà‡∏≤‡∏¢‡∏£‡∏π‡∏õ / ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏≤‡∏Å gallery
2. ‡∏£‡∏π‡∏õ‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏ô preview
3. [‡πÉ‡∏´‡∏°‡πà] ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å ReferenceDetectorService.detectFromImage()
4. [‡πÉ‡∏´‡∏°‡πà] ‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠ ‚Üí ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å ScaleCalibrationService.calibrate()
5. [‡πÉ‡∏´‡∏°‡πà] ‡πÅ‡∏™‡∏î‡∏á ArRulerOverlay ‡∏ó‡∏±‡∏ö‡∏£‡∏π‡∏õ
6. [‡πÉ‡∏´‡∏°‡πà] ‡πÅ‡∏™‡∏î‡∏á CalibrationBadge
7. User ‡∏Å‡∏î "Save & Analyze"
8. [‡πÉ‡∏´‡∏°‡πà] ‡∏™‡πà‡∏á calibrationHint ‡πÑ‡∏õ‡∏û‡∏£‡πâ‡∏≠‡∏° Gemini request
```

**‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°:**
- State variables: `_calibrationResult`, `_isDetecting`
- ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å detect ‡πÉ‡∏ô `initState` (‡∏´‡∏•‡∏±‡∏á image ready)
- Wrap Image widget ‡∏î‡πâ‡∏ß‡∏¢ `ArRulerOverlay`
- ‡∏™‡πà‡∏á `CalibrationResult.toPromptHint()` ‡πÑ‡∏õ‡∏Å‡∏±‡∏ö analysis request

---

### S6. Integrate Detection ‡πÉ‡∏ô Gallery Scanner

**‡πÑ‡∏ü‡∏•‡πå:** `lib/features/scanner/scan_controller.dart`

**Flow ‡πÉ‡∏´‡∏°‡πà:**
```
1. VisionProcessor detect "food" label ‚úÖ (‡πÄ‡∏î‡∏¥‡∏°)
2. [‡πÉ‡∏´‡∏°‡πà] ReferenceDetectorService.detectFromImage() 
3. [‡πÉ‡∏´‡∏°‡πà] ‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠ reference ‚Üí ScaleCalibrationService.calibrate()
4. [‡πÉ‡∏´‡∏°‡πà] ‡πÄ‡∏Å‡πá‡∏ö calibration data ‡πÉ‡∏ô FoodEntry
5. Gemini analyze later ‚Üí ‡πÉ‡∏ä‡πâ calibrationHint ‡πÉ‡∏ô prompt
```

---

### S7. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Phase 2

1. ‡∏ñ‡πà‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡∏≠‡∏≤‡∏´‡∏≤‡∏£ + ‡∏ä‡πâ‡∏≠‡∏ô ‚Üí ‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡πà‡∏≤ overlay ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≠‡∏ö‡∏£‡∏≠‡∏ö‡∏ä‡πâ‡∏≠‡∏ô
2. ‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡πà‡∏≤ CalibrationBadge ‡πÅ‡∏™‡∏î‡∏á "Calibrated" ‡∏´‡∏£‡∏∑‡∏≠ "Estimated"
3. ‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡πà‡∏≤ confidence < 65% ‚Üí ‡πÑ‡∏°‡πà‡πÅ‡∏™‡∏î‡∏á overlay (‡∏™‡πà‡∏á‡∏õ‡∏Å‡∏ï‡∏¥)
4. ‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡πà‡∏≤ Gemini ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö calibration hint ‡πÉ‡∏ô prompt
5. ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö: ‡∏£‡∏π‡∏õ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô ‡∏°‡∏µ‡∏ä‡πâ‡∏≠‡∏ô vs ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ä‡πâ‡∏≠‡∏ô ‚Üí serving_grams ‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡πÑ‡∏´‡∏°

---

## Phase 3: Real-time AR Camera (S8-S10)

### S8. Implement CameraFrameProcessor

**‡πÑ‡∏ü‡∏•‡πå:** `lib/core/ar_scale/services/camera_frame_processor.dart`

**‡πÅ‡∏Å‡πâ TODO:**
```dart
Future<void> processFrame(...) async {
  _isProcessing = true;
  _lastProcessedMs = now;
  
  try {
    final detected = await ReferenceDetectorService.instance
        .detectFromCameraFrame(
          imageBytes: imageBytes,
          imageSize: Size(width.toDouble(), height.toDouble()),
          rotation: rotation,
          rawFormat: rawFormat,
          bytesPerRow: bytesPerRow,
        );
    
    lastDetectedObject = detected;
    onReferenceDetected?.call(detected);
    
    if (detected != null && detected.confidence >= 0.65) {
      final calibration = ScaleCalibrationService.calibrate(
        referenceObject: detected,
        imageWidth: width.toDouble(),
        imageHeight: height.toDouble(),
      );
      lastCalibration = calibration;
      onCalibrationReady?.call(calibration);
    }
  } catch (e) {
    debugPrint('[CameraFrameProcessor] Error: $e');
  } finally {
    _isProcessing = false;
  }
}
```

---

### S9. Integrate Real-time Detection ‡πÉ‡∏ô CameraScreen

**‡πÑ‡∏ü‡∏•‡πå:** `lib/features/camera/presentation/camera_screen.dart`

**‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°:**

1. State variables:
   ```dart
   CameraFrameProcessor? _frameProcessor;
   DetectedReferenceObject? _detectedRef;
   CalibrationResult? _liveCalibration;
   bool _isScanning = true;
   ```

2. ‡πÉ‡∏ô `_initializeCamera()` ‡∏´‡∏•‡∏±‡∏á initialize ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à:
   ```dart
   _frameProcessor = CameraFrameProcessor(
     onReferenceDetected: (ref) {
       if (mounted) setState(() => _detectedRef = ref);
     },
     onCalibrationReady: (cal) {
       if (mounted) setState(() => _liveCalibration = cal);
     },
   );
   
   // ‡πÄ‡∏£‡∏¥‡πà‡∏° image stream
   _cameraController!.startImageStream((CameraImage image) {
     if (!_isScanning) return;
     _frameProcessor!.processFrame(
       imageBytes: image.planes[0].bytes,
       width: image.width,
       height: image.height,
       rotation: _cameras![0].sensorOrientation,
       rawFormat: image.format.raw,
       bytesPerRow: image.planes[0].bytesPerRow,
     );
   });
   ```

3. ‡πÉ‡∏ô `build()` Stack, ‡πÄ‡∏û‡∏¥‡πà‡∏° overlay:
   ```dart
   // Live reference indicator
   if (_detectedRef != null)
     Positioned(
       top: 100,
       left: 0,
       right: 0,
       child: Center(
         child: ReferenceObjectIndicator(
           objectType: _detectedRef!.type,
           confidence: _detectedRef!.confidence,
         ),
       ),
     ),
   
   // Live bounding box
   if (_liveCalibration != null && _liveCalibration!.shouldUseCalibration)
     LiveReferenceBoundingBox(
       boundingRect: _convertToDisplayRect(_detectedRef!.boundingBox),
       tier: _liveCalibration!.tier,
     ),
   ```

4. ‡πÉ‡∏ô `_takePicture()`:
   ```dart
   // ‡∏´‡∏¢‡∏∏‡∏î image stream ‡∏Å‡πà‡∏≠‡∏ô‡∏ñ‡πà‡∏≤‡∏¢
   _isScanning = false;
   await _cameraController!.stopImageStream();
   
   // ... take picture ...
   
   // ‡∏™‡πà‡∏á calibration ‡πÑ‡∏õ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏£‡∏π‡∏õ
   Navigator.of(context).pop({
     'file': File(filePath),
     'calibration': _liveCalibration,
   });
   ```

5. Handle `_convertToDisplayRect()`:
   ```dart
   Rect _convertToDisplayRect(BoundingBoxData bbox) {
     // ‡πÅ‡∏õ‡∏•‡∏á camera frame coordinates ‚Üí display coordinates
     // ‡∏ï‡πâ‡∏≠‡∏á handle rotation, mirroring, ‡πÅ‡∏•‡∏∞ FittedBox scaling
   }
   ```

---

### S10. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Phase 3

1. ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á ‚Üí ‡∏™‡πà‡∏≠‡∏á‡∏≠‡∏≤‡∏´‡∏≤‡∏£ + ‡∏ä‡πâ‡∏≠‡∏ô ‚Üí ‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡πà‡∏≤ overlay ‡πÅ‡∏™‡∏î‡∏á real-time
2. ‡∏Ç‡∏¢‡∏±‡∏ö‡∏Å‡∏•‡πâ‡∏≠‡∏á ‚Üí overlay ‡∏ï‡πâ‡∏≠‡∏á track ‡∏ï‡∏≤‡∏°
3. ‡πÄ‡∏≠‡∏≤‡∏ä‡πâ‡∏≠‡∏ô‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÄ‡∏ü‡∏£‡∏° ‚Üí overlay ‡∏ï‡πâ‡∏≠‡∏á‡∏´‡∏≤‡∏¢‡πÑ‡∏õ
4. Confidence < 65% ‚Üí overlay ‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏°‡πà‡πÅ‡∏™‡∏î‡∏á
5. ‡∏ñ‡πà‡∏≤‡∏¢‡∏£‡∏π‡∏õ ‚Üí calibration ‡∏ï‡πâ‡∏≠‡∏á‡∏ñ‡∏π‡∏Å‡∏™‡πà‡∏á‡πÑ‡∏õ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏£‡∏π‡∏õ
6. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö performance: FPS ‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏°‡πà drop ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤ 20

---

## ‚ö†Ô∏è Edge Cases ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á Handle

| Case | ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ |
|------|----------|
| ‡∏ä‡πâ‡∏≠‡∏ô‡∏ñ‡∏π‡∏Å‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏ö‡∏±‡∏á‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô | ‡πÉ‡∏ä‡πâ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡πá‡∏ô + ‡∏•‡∏î confidence 20% |
| ‡∏°‡∏µ‡∏ä‡πâ‡∏≠‡∏ô + ‡∏™‡πâ‡∏≠‡∏° ‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô | ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡∏ß‡∏ó‡∏µ‡πà confidence ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î |
| ‡∏ä‡πâ‡∏≠‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏Ñ‡∏ô‡∏•‡∏∞‡∏£‡∏∞‡∏ô‡∏≤‡∏ö‡∏Å‡∏±‡∏ö‡∏à‡∏≤‡∏ô | adjustConfidenceForPerspective() ‡∏•‡∏î confidence |
| ‡∏£‡∏π‡∏õ‡∏ñ‡πà‡∏≤‡∏¢‡πÄ‡∏≠‡∏µ‡∏¢‡∏á / ‡∏´‡∏°‡∏∏‡∏ô | ‡πÉ‡∏ä‡πâ EXIF rotation + adjust bounding box |
| ML Kit ‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ö‡∏ô Windows | Skip detection, ‡∏™‡πà‡∏á Gemini ‡∏õ‡∏Å‡∏ï‡∏¥ (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô VisionProcessor) |
| ‡∏ä‡πâ‡∏≠‡∏ô‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏°‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô | Gemini ‡∏à‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô/‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏ô Phase 1 prompt |

---

## üìÅ ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà Senior ‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ

### Phase 1 (‡πÅ‡∏Å‡πâ 1 ‡πÑ‡∏ü‡∏•‡πå):
- `lib/core/ar_scale/services/scale_calibration_service.dart` ‚Äî implement logic
- `lib/core/ai/gemini_service.dart` ‚Äî ‡πÄ‡∏û‡∏¥‡πà‡∏° prompt section + parameter

### Phase 2 (‡πÅ‡∏Å‡πâ 3 ‡πÑ‡∏ü‡∏•‡πå):
- `lib/core/ar_scale/services/reference_detector_service.dart` ‚Äî ML Kit integration
- `lib/features/health/presentation/image_analysis_preview_screen.dart` ‚Äî overlay + detection
- `lib/features/scanner/scan_controller.dart` ‚Äî gallery scan integration

### Phase 3 (‡πÅ‡∏Å‡πâ 2 ‡πÑ‡∏ü‡∏•‡πå):
- `lib/core/ar_scale/services/camera_frame_processor.dart` ‚Äî real-time processing
- `lib/features/camera/presentation/camera_screen.dart` ‚Äî live overlay + stream

---

## üîë Dependency Order

```
Phase 1 ‚Üí ‡πÑ‡∏°‡πà depend ‡∏≠‡∏∞‡πÑ‡∏£, ‡∏ó‡∏≥‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢
Phase 2 ‚Üí depend Phase 1 (‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ calibration logic ‡∏Å‡πà‡∏≠‡∏ô)
Phase 3 ‚Üí depend Phase 2 (‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ detector service ‡∏Å‡πà‡∏≠‡∏ô)
```
